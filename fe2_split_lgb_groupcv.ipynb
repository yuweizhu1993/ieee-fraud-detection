{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuyuwei/Library/Python/3.7/lib/python/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#### basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#### Visulization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "#### ML\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit, train_test_split, GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "# import xgboost as xgb\n",
    "\n",
    "#### Others\n",
    "import datetime\n",
    "import os, warnings, random\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "test_X = []\n",
    "for i in range(1,6):\n",
    "    train_path = 'train_FE2_mini_' + str(i) + '.pkl'\n",
    "    test_path = 'test_FE2_mini_' + str(i) + '.pkl'\n",
    "    train = pd.read_pickle(train_path)\n",
    "    train_Y.append(train[['isFraud']])\n",
    "    train_X.append(train.drop(['isFraud'], axis = 1, inplace = True))\n",
    "    test_X.append(pd.read_pickle(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_m = pd.read_csv('DT_M_train.csv',index_col=0,header=None)\n",
    "test_X_m = pd.read_csv('DT_M_test.csv',index_col=0,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "SEED = 42\n",
    "LOCAL_TEST = False\n",
    "TARGET = 'isFraud'\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(train_X, train_Y, test_X, lgb_params, NFOLDS = 5):\n",
    "    folds = GroupKFold(n_splits=NFOLDS)\n",
    " \n",
    "    split_groups = train_X_m\n",
    "\n",
    "    tt_df = np.zeros(test_X.shape[0])\n",
    "    \n",
    "    oof = np.zeros(len(X))\n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        start_time = time.time()\n",
    "        X_train, X_valid = train_X[columns].iloc[train_index], train_X[columns].iloc[valid_index]\n",
    "        y_train, y_valid = train_Y.iloc[train_index], train_Y.iloc[valid_index]\n",
    "\n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "        # Train\n",
    "        clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=250, early_stopping_rounds=150)\n",
    "\n",
    "        # Record feature importance\n",
    "        feature_importances['fold_{}'.format(fold_n + 1)] = clf.feature_importance()\n",
    "\n",
    "        # Predict and put OOF predicted data into holdout position\n",
    "        y_pred_valid = clf.predict(X_valid)\n",
    "        y_pred_valid_vectors[valid_index] = y_pred_valid\n",
    "\n",
    "        print(\"Fold {} | AUC: {}\".format((fold_n + 1),roc_auc_score(y_valid, y_pred_valid)))\n",
    "        print('time used {}'.format(time.time()-start_time))\n",
    "\n",
    "        # Averaging auc score\n",
    "        score += roc_auc_score(y_valid, y_pred_valid) / 5\n",
    "\n",
    "        # Averaging predicting value\n",
    "        y_pred_test_vectors += clf.predict(test_X) / 5\n",
    "\n",
    "        del X_train, X_valid, y_train, y_valid\n",
    "\n",
    "        #gabage collector\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, y, test_X, lgb_params, train_X_m,NFOLDS=6):\n",
    "    \n",
    "    folds = GroupKFold(n_splits=NFOLDS)\n",
    "\n",
    " \n",
    "    split_groups = train_X_m\n",
    "\n",
    "    tt_df = np.zeros(test_X.shape[0])   \n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups=split_groups)):\n",
    "        print('Fold:',fold_)\n",
    "        tr_x, tr_y = X.iloc[trn_idx,:], y.iloc[trn_idx]\n",
    "        vl_x, vl_y = X.iloc[val_idx,:], y.iloc[val_idx]\n",
    "            \n",
    "        print(len(tr_x),len(vl_x))\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "        vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
    "\n",
    "        estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            tr_data,\n",
    "            valid_sets = [tr_data, vl_data],\n",
    "            verbose_eval = 200,\n",
    "        )   \n",
    "        \n",
    "        pp_p = estimator.predict(test_X)\n",
    "        tt_df += pp_p/NFOLDS\n",
    "        \n",
    "        oof_preds = estimator.predict(vl_x)\n",
    "        oof[val_idx] = (oof_preds - oof_preds.min())/(oof_preds.max() - oof_preds.min())\n",
    "\n",
    "        if LOCAL_TEST:\n",
    "            feature_imp = pd.DataFrame(sorted(zip(estimator.feature_importance(),X.columns)), columns=['Value','Feature'])\n",
    "            print(feature_imp)\n",
    "        \n",
    "        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n",
    "        gc.collect()\n",
    "        \n",
    "    print('OOF AUC:', metrics.roc_auc_score(y, oof))\n",
    "    if LOCAL_TEST:\n",
    "        print('Holdout AUC:', metrics.roc_auc_score(tt_df[TARGET], tt_df['prediction']))\n",
    "    \n",
    "    return oof,tt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model params\n",
    "lgb_params = {\n",
    "            'objective':'binary',\n",
    "            'boosting_type':'gbdt',\n",
    "            'metric':'auc',\n",
    "            'n_jobs':-1,\n",
    "            'learning_rate':0.01,\n",
    "            'num_leaves': 491,\n",
    "            'max_depth':-1,\n",
    "            'tree_learner':'serial',\n",
    "            'colsample_bytree': 0.5,\n",
    "             'subsample_freq':1,\n",
    "             'subsample':0.7,\n",
    "             'n_estimators':5000,\n",
    "              'max_bin':412,\n",
    "              'verbose':-1,\n",
    "              'seed': SEED,\n",
    "              'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "453219 137321\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[200]\ttraining's auc: 0.971371\tvalid_1's auc: 0.883661\n",
      "[400]\ttraining's auc: 0.991777\tvalid_1's auc: 0.896595\n",
      "[600]\ttraining's auc: 0.998058\tvalid_1's auc: 0.903738\n",
      "[800]\ttraining's auc: 0.999519\tvalid_1's auc: 0.907277\n",
      "[1000]\ttraining's auc: 0.999866\tvalid_1's auc: 0.909738\n",
      "[1200]\ttraining's auc: 0.999969\tvalid_1's auc: 0.911713\n",
      "[1400]\ttraining's auc: 0.999994\tvalid_1's auc: 0.913595\n",
      "[1600]\ttraining's auc: 0.999999\tvalid_1's auc: 0.914867\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.916259\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.917384\n",
      "[2200]\ttraining's auc: 1\tvalid_1's auc: 0.9184\n",
      "[2400]\ttraining's auc: 1\tvalid_1's auc: 0.919006\n",
      "Early stopping, best iteration is:\n",
      "[2183]\ttraining's auc: 1\tvalid_1's auc: 0.918291\n",
      "Fold: 1\n",
      "488908 101632\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[200]\ttraining's auc: 0.971468\tvalid_1's auc: 0.919061\n",
      "[400]\ttraining's auc: 0.991612\tvalid_1's auc: 0.931662\n",
      "[600]\ttraining's auc: 0.998173\tvalid_1's auc: 0.938389\n",
      "[800]\ttraining's auc: 0.999567\tvalid_1's auc: 0.942016\n",
      "[1000]\ttraining's auc: 0.99988\tvalid_1's auc: 0.943897\n",
      "[1200]\ttraining's auc: 0.999971\tvalid_1's auc: 0.944816\n",
      "[1400]\ttraining's auc: 0.999995\tvalid_1's auc: 0.945511\n",
      "[1600]\ttraining's auc: 1\tvalid_1's auc: 0.946018\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.946351\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.946659\n",
      "[2200]\ttraining's auc: 1\tvalid_1's auc: 0.946775\n",
      "Early stopping, best iteration is:\n",
      "[2023]\ttraining's auc: 1\tvalid_1's auc: 0.946689\n",
      "Fold: 2\n",
      "497955 92585\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[200]\ttraining's auc: 0.968607\tvalid_1's auc: 0.915966\n",
      "[400]\ttraining's auc: 0.990797\tvalid_1's auc: 0.92824\n",
      "[600]\ttraining's auc: 0.99787\tvalid_1's auc: 0.934347\n",
      "[800]\ttraining's auc: 0.999481\tvalid_1's auc: 0.938121\n",
      "[1000]\ttraining's auc: 0.999852\tvalid_1's auc: 0.940118\n",
      "[1200]\ttraining's auc: 0.999962\tvalid_1's auc: 0.941276\n",
      "[1400]\ttraining's auc: 0.999993\tvalid_1's auc: 0.941924\n",
      "[1600]\ttraining's auc: 0.999999\tvalid_1's auc: 0.942528\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.943148\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.943387\n",
      "[2200]\ttraining's auc: 1\tvalid_1's auc: 0.943706\n",
      "[2400]\ttraining's auc: 1\tvalid_1's auc: 0.943997\n",
      "Early stopping, best iteration is:\n",
      "[2195]\ttraining's auc: 1\tvalid_1's auc: 0.943684\n",
      "Fold: 3\n",
      "501214 89326\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[200]\ttraining's auc: 0.968045\tvalid_1's auc: 0.911338\n",
      "[400]\ttraining's auc: 0.990042\tvalid_1's auc: 0.926433\n",
      "[600]\ttraining's auc: 0.997683\tvalid_1's auc: 0.935411\n",
      "[800]\ttraining's auc: 0.999444\tvalid_1's auc: 0.939854\n",
      "[1000]\ttraining's auc: 0.999839\tvalid_1's auc: 0.942199\n",
      "[1200]\ttraining's auc: 0.999955\tvalid_1's auc: 0.943257\n",
      "[1400]\ttraining's auc: 0.99999\tvalid_1's auc: 0.943609\n",
      "[1600]\ttraining's auc: 0.999998\tvalid_1's auc: 0.943886\n",
      "[1800]\ttraining's auc: 0.999999\tvalid_1's auc: 0.943938\n",
      "[2000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.944012\n",
      "Early stopping, best iteration is:\n",
      "[1901]\ttraining's auc: 0.999999\tvalid_1's auc: 0.944049\n",
      "Fold: 4\n",
      "504519 86021\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[200]\ttraining's auc: 0.968417\tvalid_1's auc: 0.929658\n",
      "[400]\ttraining's auc: 0.990516\tvalid_1's auc: 0.940532\n",
      "[600]\ttraining's auc: 0.997676\tvalid_1's auc: 0.945576\n",
      "[800]\ttraining's auc: 0.999409\tvalid_1's auc: 0.94808\n",
      "[1000]\ttraining's auc: 0.999827\tvalid_1's auc: 0.949576\n",
      "[1200]\ttraining's auc: 0.999955\tvalid_1's auc: 0.95035\n",
      "[1400]\ttraining's auc: 0.999991\tvalid_1's auc: 0.950972\n",
      "[1600]\ttraining's auc: 0.999999\tvalid_1's auc: 0.951477\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.951702\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.951937\n",
      "[2200]\ttraining's auc: 1\tvalid_1's auc: 0.951955\n",
      "[2400]\ttraining's auc: 1\tvalid_1's auc: 0.951955\n",
      "Early stopping, best iteration is:\n",
      "[2183]\ttraining's auc: 1\tvalid_1's auc: 0.951982\n",
      "Fold: 5\n",
      "506885 83655\n",
      "Training until validation scores don't improve for 250 rounds.\n",
      "[200]\ttraining's auc: 0.967904\tvalid_1's auc: 0.922369\n",
      "[400]\ttraining's auc: 0.989651\tvalid_1's auc: 0.93745\n",
      "[600]\ttraining's auc: 0.99751\tvalid_1's auc: 0.946266\n",
      "[800]\ttraining's auc: 0.999365\tvalid_1's auc: 0.95094\n",
      "[1000]\ttraining's auc: 0.99981\tvalid_1's auc: 0.953428\n",
      "[1200]\ttraining's auc: 0.999945\tvalid_1's auc: 0.954923\n",
      "[1400]\ttraining's auc: 0.999988\tvalid_1's auc: 0.955928\n",
      "[1600]\ttraining's auc: 0.999998\tvalid_1's auc: 0.95646\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.956921\n",
      "[2000]\ttraining's auc: 1\tvalid_1's auc: 0.957146\n",
      "[2200]\ttraining's auc: 1\tvalid_1's auc: 0.957318\n",
      "[2400]\ttraining's auc: 1\tvalid_1's auc: 0.957245\n",
      "Early stopping, best iteration is:\n",
      "[2154]\ttraining's auc: 1\tvalid_1's auc: 0.957326\n",
      "OOF AUC: 0.9426133240915605\n"
     ]
    }
   ],
   "source": [
    "lgb_params['learning_rate'] = 0.005\n",
    "lgb_params['n_estimators'] = 10000\n",
    "lgb_params['early_stopping_rounds'] = 250    \n",
    "oof, test_predictions = make_predictions(train_X, train_Y, test_X, lgb_params, train_X_m, NFOLDS=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00016624, 0.00131395, 0.0005106 , ..., 0.00140933, 0.00218048,\n",
       "       0.00163354])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv('/home/highburyglory95/sample_submission.csv')\n",
    "\n",
    "pred['isFraud'] = test_predictions\n",
    "pred.to_csv(\"submission_fe2_lgb_gcv_.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
